{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "local-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "hungry-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_function(x):\n",
    "    k=nltk.FreqDist(x)   \n",
    "    return list(k.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "qualified-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class voteclassifier(ClassifierI):\n",
    "    def __init__(self,*classifiers):\n",
    "        self._classifiers = classifiers\n",
    "        \n",
    "    def classify(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return (mode_function(votes))\n",
    "    \n",
    "    def confidence(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode_function(votes)) ## how many time the mode value has appeared in the function\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "regulated-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_f = open(\"documents_twitter.pickle\",\"rb\")\n",
    "documents  = pickle.load(documents_f)\n",
    "documents_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "governing-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features_5 = open(\"word_features.pickle\",'rb')\n",
    "word_features = pickle.load(word_features_5)\n",
    "word_features_5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "suburban-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "        # words=set(document)  ## you cannot use this, since the input is now sring and not words as seperate\n",
    "        # but the above will work but with less accurcay\n",
    "        \n",
    "    words = word_tokenize(document)\n",
    "    features={}   ## created a dictionary\n",
    "    for w in word_features:\n",
    "        features[w]=(w in words)  ## will set the value a s 1 if there else 0\n",
    "        ## will create a boolean value for each word\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "premier-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset_5 = open(\"featuresets_twitter.pickle\",'rb')\n",
    "featuresets = pickle.load(featureset_5)\n",
    "featureset_5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "protecting-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"originalnaivebayes_twitter.pickle\", \"rb\")\n",
    "classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"MNB_classifier_twitter.pickle\", \"rb\")\n",
    "MNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"BernoulliNB_classifier_twitter.pickle\", \"rb\")\n",
    "BernoulliNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"LogisticRegression_classifier_twitter.pickle\", \"rb\")\n",
    "LogisticRegression_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"LinearSVC_classifier_twitter.pickle\", \"rb\")\n",
    "LinearSVC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"SGDC_classifier_twitter.pickle\", \"rb\")\n",
    "SGDC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "plastic-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voted_classifier = voteclassifier(classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sophisticated-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "initial-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "## just save the file\n",
    "## and use the same file name in other script so as to run all the programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-command",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "copyrighted-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Shankii\\\\Documents\\\\NLTK'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-infrared",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-terrorism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-cuisine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-begin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-contest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-status",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-novel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-audio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-holiday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
